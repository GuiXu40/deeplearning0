{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOItuEmSabuNtQ4wMY4Sk+s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuiXu40/deeplearning0/blob/main/Basic_code/Basic_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A2VPKFJlzxe",
        "outputId": "4a023ac3-b241-44b0-c892-0696ba53b2e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 导包"
      ],
      "metadata": {
        "id": "Q0McOwhXl8IH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "7Q-Gh-TUmd1H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 网络结构"
      ],
      "metadata": {
        "id": "V-WCxoDimsvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = [1, 28, 28]\n",
        "latent_dim = 64\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(latent_dim, 128, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 256, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 512, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 1024, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(1024, np.prod(image_size, dtype=np.int32), bias=True),\n",
        "        nn.Sigmoid() ,\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    output = self.model(x)\n",
        "    return output.reshape(x.shape[0], *image_size) # 输出图片\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(np.prod(image_size, dtype=np.int32), 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 32),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(32, 1),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def forward(self, image):\n",
        "    prob = self.model(image.reshape(image.shape[0], -1))\n",
        "    return prob\n"
      ],
      "metadata": {
        "id": "LxoZvb7cmque"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 加载数据"
      ],
      "metadata": {
        "id": "GP2q7dKImwqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "dataset = torchvision.datasets.MNIST(\"./data\", train=True, download=True,\n",
        "                                     transform=torchvision.transforms.Compose([\n",
        "                                         torchvision.transforms.Resize(28),\n",
        "                                         torchvision.transforms.ToTensor(),\n",
        "                                     ])\n",
        "                                    )\n",
        "print(len(dataset)) # 60000\n",
        "print(dataset[0][0].shape) #[1, 28, 28]\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4vjeP5CmzK7",
        "outputId": "08d5f5e2-7e8a-48f7-ba85-e65fa4c80c1c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "torch.Size([1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 优化器 / 损失函数\n",
        "\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0003, betas=(0.4, 0.8), weight_decay=0.0001)\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0003, betas=(0.4, 0.8), weight_decay=0.0001)\n",
        "\n",
        "loss_fn = nn.BCELoss()"
      ],
      "metadata": {
        "id": "QYAFwweHDDN4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "# 训练\n",
        "epochs = 20\n",
        "labels_one = torch.ones(batch_size, 1)\n",
        "labels_zero = torch.zeros(batch_size, 1)\n",
        "if use_gpu:\n",
        "    print(\"use gpu for training\")\n",
        "    generator = generator.cuda()\n",
        "    discriminator = discriminator.cuda()\n",
        "    loss_fn = loss_fn.cuda()\n",
        "    labels_one = labels_one.to(\"cuda\")\n",
        "    labels_zero = labels_zero.to(\"cuda\")\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i, mini_batch in enumerate(dataloader):\n",
        "    gt_images, _ = mini_batch\n",
        "\n",
        "    z = torch.rand(batch_size, latent_dim)\n",
        "    if use_gpu:\n",
        "      gt_images = gt_images.to(\"cuda\")\n",
        "      z = z.to(\"cuda\")\n",
        "    pred_images = generator(z)\n",
        "    g_optimizer.zero_grad()\n",
        "\n",
        "    #recons_loss = torch.abs(pred_images-gt_images).mean()\n",
        "    #g_loss = recons_loss*0.05 + loss_fn(discriminator(pred_images), labels_one)\n",
        "    g_loss = loss_fn(discriminator(pred_images), labels_one)\n",
        "    g_loss.backward()\n",
        "    g_optimizer.step()\n",
        "\n",
        "    d_optimizer.zero_grad()\n",
        "    real_loss = loss_fn(discriminator(gt_images), labels_one)\n",
        "    fake_loss = loss_fn(discriminator(pred_images.detach()), labels_zero)\n",
        "    d_loss = (real_loss + fake_loss)\n",
        "\n",
        "    # 观察real_loss与fake_loss，同时下降同时达到最小值，并且差不多大，说明D已经稳定了\n",
        "\n",
        "    d_loss.backward()\n",
        "    d_optimizer.step()\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        # print(f\"step:{len(dataloader)*epoch+i}, recons_loss:{recons_loss.item()}, g_loss:{g_loss.item()}, d_loss:{d_loss.item()}, real_loss:{real_loss.item()}, fake_loss:{fake_loss.item()}\")\n",
        "        print(f\"step:{len(dataloader)*epoch+i}, g_loss:{g_loss.item()}, d_loss:{d_loss.item()}, real_loss:{real_loss.item()}, fake_loss:{fake_loss.item()}\")\n",
        "\n",
        "    if i % 400 == 0:\n",
        "        image = pred_images[:16].data\n",
        "        torchvision.utils.save_image(image, f\"image_{len(dataloader)*epoch+i}.png\", nrow=4)\n"
      ],
      "metadata": {
        "id": "1H9T30-XEIlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f sample_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUP8MmS-X1ET",
        "outputId": "31ccc740-393f-4107-c6a6-cc3def430771"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'sample_data': Is a directory\n"
          ]
        }
      ]
    }
  ]
}