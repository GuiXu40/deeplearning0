{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMq6CDnknlg7OvtgT82qR/9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuiXu40/deeplearning0/blob/main/Basic_code/Transformer%E6%89%8B%E5%86%99%E5%AE%9E%E7%8E%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9TSiGriRGWxT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step1. 构建词向量\n",
        "# 关于word embedding, 以序列建模为例\n",
        "# 考虑source sentence 和 target sentence\n",
        "# 构建序列，序列的字符以其在词表中的索引形式出现。\n",
        "# 这里随机初始化序列，在实际利用中是通过词表构建\n",
        "batch_size = 2\n",
        "\n",
        "# 词表大小\n",
        "max_num_src_words = 8\n",
        "max_num_tgt_words = 8 # 句子的最大长度，通过这个可以求mask矩阵\n",
        "model_dim = 8\n",
        "\n",
        "# 序列的最大长度\n",
        "max_src_seq_len = 5\n",
        "max_tgt_seq_len = 5\n",
        "max_position_len = 5\n",
        "\n",
        "# 初始化 src,tgt 随机序列\n",
        "# src_word: (batch_size, 单词在词表中索引的位置)\n",
        "src_len = torch.Tensor([2, 4]).to(torch.int32) # batch中每个句子的长度，然后构建索引\n",
        "tgt_len = torch.Tensor([4, 3]).to(torch.int32)\n",
        "# 随机初始化src,tgt序列，构建batch， 并padding，padding默认值为0\n",
        "src_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(max_num_src_words, (L,)), (0, max(src_len) - L)), 0) for L in src_len])\n",
        "#print(src_seq.shape) # [2, 4]\n",
        "#print(src_seq)\n",
        "tgt_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(max_num_tgt_words, (L,)), (0, max(tgt_len) - L)), 0) for L in tgt_len])\n",
        "print(tgt_seq.shape) # [2, 4]\n",
        "print(tgt_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMIl0HywGeVO",
        "outputId": "84e40e4c-9702-4b48-9ff6-1bdc04fcc2dd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4])\n",
            "tensor([[2, 6, 7, 4],\n",
            "        [4, 0, 1, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step2. 构建word embedding\n",
        "src_embedding_table = nn.Embedding(max_num_src_words+1, model_dim)\n",
        "tgt_embedding_table = nn.Embedding(max_num_tgt_words+1, model_dim)\n",
        "src_embedding = src_embedding_table(src_seq)\n",
        "tgt_embedding = tgt_embedding_table(tgt_seq)\n",
        "print(src_embedding.shape) # [2, 4, 8]\n",
        "print(tgt_embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AZn-JbPKaOO",
        "outputId": "5fd7492a-a422-4bbe-c5c8-32134711a62d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4, 8])\n",
            "torch.Size([2, 4, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAABzCAYAAAD5RVeEAAAgAElEQVR4nO3df2hbZ7rg8e/dKVSQwjFkGJUWokuGkZiUyLSXyNMh1iUQiQ5UJsNEaSHWbaHWZkjkdskoGW7iZGmtlk3llO3ImW2rhk3tlrZSoEEypFGWZq2wk7UCHiRzM5EvKT7Z7eBzaRYJHKwwuTz7x5Ft2ZYTN7EjK3k/ILCl9xy/R+fH8573fc/jvxMRQVEURVGazH9odAUURVEU5V6oAKYoiqI0JRXAFEVRlKakApiiKIrSlFQAUxRFUZqSCmCKoihKU1IBTFEURWlKKoApiqIoTUkFMEVR7pFO5miAjl97aXW0sevdLOUFJYyxLMUbDamc8ghQAUxRlHuif3KAvie6SXyVIfW2k/w7HQQ/0+cK3MwQ2xnkyOkClcZVU3mIqQCmKMo9KJD+OEMLcAuw7QwStELmgzSFmSLrvESKRRJ7nFgaV1HlIaYCmKIo9+BxHm+xkr+YJV8GsGF7HhjTmVzYj6goq0QFMOUhUCb7ltl9tRa7qspD3bT+oXD3gk3FQTBdpJgO49aASpHiJcDjxKaBfuYA3W8EcT8XIbvMnVL4g5vuoeVEvwqV28Dtyprc38qD07wB7M/9tLa00HKHV6unm76h4uKD/C9xvHdZtvYVOG00YgsfXrcNChdzKzS4XyH3rp/g7TCx3bY12FWlk/okQ+B55xKfVyiXm/8yrJ+J04eXyFE/jhtp+r92Edphw7ipU/5/y1hBJUvqhA33c9odixXec9DS8iStzzhoeaaf8ZWpvtKspMlNfN4pmqaJtv+clGo/KF2VgT120TRNPMfzMl1n2clkddlXEjK58MO/lST/sfl5NLdq1X8k5U+0m9/71pjk73Nd05d6pd0elnPfr0jVVt61AfHX287pkkzkBuTwi/b6x19V6dJHEt7pEteLPvFs90v4g5H5x3mDy4mITOei4tkelkSxepb9bVpKU5OS2qtJ+z8PL7ncvHVke8W+N7WsslKIiUvTRDsyXPe8Vh4dTR7ASnJuvyaapknn5xOLP85FzQuldliGFx3p0zJ8xFy2/cQSl9HSOQlrPhm4ttL1frSVMmFxapo4D55b3gVrSRMysFOT9vfvNwyunolTvgX1m5TEK5rYf+GTzp2epRtQIjL5VZfYNY9Ec9WDd2pEots1sS9orDWqnIjIdCEmna/0yrAuIlKSkU9TcnVazMCteSQ6WpLp0t3CjHkuhtLLOxpmGp6dyaXCvvKoaPIAlpeoXRNNa5dYYfGn098crgawTkl8t3jZ2FZNNM2+4A5rWqZnz7cR6dW6JKXOkzVpOtsr9jXdwMhLbGv9Y1NE5hpY9QLY9LD02jXRdiektmlm9jjUHLONKicioieky+6XaHpYhrPDMpyJSWf1bjN/ol20nQNydTQm/iN3uQv7PiUhLSznlhW/Zhqea3m/Kw9K846BAXybJ2sAuHH+bPHH43/Jmj9sbsPx1OJlM2MAflyb5942Tgdp/UPO/OWvOkWrA5t1xWuu3LcKuQuDGJu9tG5sdF2WMJYl8WQQ3+a7F128bI5BA9hkw1bztu3vHYBB/EKuseUoEn8tSNLIEOnsoMPXQYe/h7TTXM72szZsk0mOfFwh1OXmTiNb5UsZMvt95mSQuxon9yVgdeNYq/tdeWAea3QF7odRyJIFeLkNx6LR+wLZzwuAldBbXSwcQi+PF8xld7TOLXsjy+CHafyH4ubvT/kZLK5a9R9eN4skj/WRLFtxW28xcnmSW7dzuI4WCegBHF05bBtB/zZIphTGRY6+Fi+R6uI96TzOS318PKpTGs9i/DREz9s9+O21O3mc3GcGvGifd6E1/36B+L4w/QUdS3sfiUNW0m9FyFyvoH/Xgu+dKJEXapcqUxyK0/9+huITFpg0aPGE6f29H8e62hVXKJ6OcOTDHJUnLFSmrHT09hH6Rf0rb+5sjCd3ZBbXbxkMPY8Bi8/QH5nfgXFFx8AFDSpnxUHwfIngUhvgiZL3LGtLyZzOEHgtWn8CTrlI8vgR4pcqWKhg3dKKYQCvOXEsZ/XKw63Rt4D3bm4My3dqwfhX6aokDnpE05wSStYZGxORkbe1avfiwtfdujImZPjjc1J/rQ32twk59/nSg+0PRknO7beLdvDc3AD71LActtdMhpk6J2FNE02LykjNklc/9ommaWK3+yR6qTRv2UUTPr5LSKemif344vGviU/94j81IRMzk3TsXTJwxVxfKR0STfPMdetN5SX2kl207b1ybqYfr/o37XtS87r2Jr/qErv9cPX4mJRz+9tFs0frT0SZHpZee72u6xp36EIcOVY9Ho+N1F+m+t01qtyKuTYgfvsS69QT0mXXxHOsekxPjUjvVq0pxr9KowNyrtjoWjz8mvgObJzCBfOn4gfddJypvn3bQP/eivvXQTJFP6663X8FcmcBrPScLxLeUl3Phx20fe3EsWRXhk7yt93kdsSIruCW3NH1DD1H+yl8p1OcchB8N064fX4FjbEspafcONbbcDwWwf27Etnj3jt225gqZN/ZRd/lH1inbT0kXnctMWW9SOGkATsMjNtgewxY58D9Gzf6zNG2roV6u6VFq9Z4d3jurmadg9bngTMjFP8awjnTFXzDQAdcGxauqUD6gwq+T2yUvzbTGgX7YwR+btZWs9qAQRIXC4Q228gc9dPzdSux0R68M6uq/s3+LxJkD/nwbzDXmzyexNgSN4+Pik7ugoF7t6vuHVblUoa+7bvQF3ZdK/PoF5NM7ovgWvhBpUDfa0GShEjtc5nH8jon7m3QN+akzfFg+vX10910H8+Q/YuL+JVB/EvtzxtZ+g73MfhFFuuxETKdDgo7vIy/lyF0L13IyrI0bwCrGcPqOxPH90OO5+tFRsYAOnDa5962aBrW9tbZC1LhZIDE0/1EXjAvpsaZCPF1IQZfuJdOoXuhM/i7PloOpkhtMUj+1kvQF8Q6miAw0/9/M0NsZzfj+5MM7HFi2xmhZ8hB5Gud6At3C2EW3IdSuFe0zk7ch5zwTjetl/pxb/fg/aUb3+9TeJc1xgGuTY67P89VqVCAOsHDSddQAotmkMwVAB+uZ+bWZnxn9gkXpipULseJnDRgd4COeeMpFSplgDS6AWyo+WgoSIcnhXebF8/pHD0b621UmexQP4FfHVhGI+JRViD9cYldf1z8jJwxFCVyGayHOnDPduNWG63Wjnnj1qvJtjNG5LoD91n3XOOpnvVuwvsKpL4o4X3OBusshN7x4t3bj/tiaNEQhrIymnYSx+wY1jY3zh/YGCtfyZEGeNE1726r5bkgyZerEa2SJfUutDpnChRIHi/ifdld9+5hVYyliZ+fzTaH/7UgVjLEv67J6rAo35wV3ysh4idSNGb4zoLrYJrMWwFc64pkP+unZ98uWl1BktcfUA00C1SK5M8A27y4Zi88FYqjSQD8dhuFC3EKgG+ba36gKRerd/c+bE/PvOmk670I3o2gX04Tf7ebXc/56ftznYeQb2RJnwzh337v4cu20XfnAjuqkyUaVG5FjGVJ/LjeJBeD7FAaAP+Wmkv/TKP1xQc5/qVTHDVwelrvut1GcYSCtQ3nRvNMtGzxE/xxD4kLzf+g+lrVpHdgFfJ/MidaLOfAWqhYSAFgfc4xb1nN7p5tKRlD8fldQGNZEriJ2B9grofHHqfFmid7IU9wixvtaRsuIH1tkjLOJVv3lk1t+C8Okvs2cJeZWvfehZh6fVGnT1WZ4kUd23+MkXk9Bjd1cp9GCPw+Sc+pAL6j7pXJlmGx3LlVO5YjCfPuqOe6nb24naCfMQA33ufmN0kqo1niADs6cD9lbpN+OU95Q4jEaIiKUeT8h90E3ssROV8g/Oz878K4kCCzP0j0PjbUamvFShpjykyXNLOqylTJ/HyTzWxINarcCsidjfHkznqTXHT0MwB+2jbNfYkzjVbfFgfa7QrlWxa0dYsWXlkVnfyQlbbOu/UKlMlfSsPzcVrXz7xno7XdSveFHD3bVui4V+Zp0gA2N/7l/rn9zkUXKZBLm6mh/M8usayRpu9wjvDH8dkgYRRHKFjcWGuiRuVyHweO58jctBPcUsZ4TENPj+P5KEFwM0CZ3IcRYoXHaXu6TCYNwS9j+DZQnanXT87iQLuewXghTmzHgkvDz4OkinPzvCrXiuQAr9OGhplvru9CifxFG5E/9eCeOUOsNhzWDIXxMtTt4pqxGl2IRdK+AMyMLa6z4drTQ+RikuBfy5RhZU7kn9hwANnrBtS5pOpXshhAqGYfVy5nSIyB62gP/o0auQ0AGpZ5FdJJf9IPVj/xt/xYAf2zIK37MvDyIMUPfFitDnyvBvG9l6Nl08J7AZ3MlzkCr8fvbzs3uwluhsiYjsFcV6lxvQA4CW5zNrbc/apkyZxsxXe2XvPTgmUzMObAOrtrK4xciANO2p6xoX/WQeBmhOxeO7n3DhDLZSlvCuN/rIj+BBROncd+qBfH5fPoTz9O4VQB1/uDc+PHN3LE34lRWNeG9UaG9GNBEu/7zO01svS/FUdf34J+PkueVnrs1eVuG2T/GKH/moZ73TiD/95F5pgXjSKFIXC94Zh3NFo3uuF4gXHcqhtxNTR6Fsk9uTYgPk0T7V4eMq7OXtO0TknoCz+clsncgIS3L571NnJsYbqqvMR2Hpbhs1Gxa+0STk/MlduTkkmZkNRep9j3JGTib9V1vD3zmTlTzvy5JKm9mnjevFvKnQkzg8NLMclPicj3KQnvScjVb3rFbu+S1LzZbma2B88HV3/gl7MSRiSqaaK9MjC73TOzx+Zmjo1Ib50ZbTNpweZnVZmQxO56+6v6IHqd7BAik5LaU82y8vaIORuyVM0msWfuAd3p0ah45v29kowc84hWOwtSqg/lbgnJwEyqpJly26OSX5hkYqnUUfVc6jVn9i14aHhG6WxY7Fq79F6ay4jRu3Xx7MhGlbsfd0sdlT/hEU0LSep7EZFpuXqqS+yz5+2EDOysziS9NiCd+xOSeNMu2tawpHSRmeNf2x6WczW/22cyv+gpCT1rl67Z/W4ej11fTVZnPtacz2/XXAum8xJ70V4zK/KchLceluGSVK9J7XPZS2bkoubM5qkV+uKUeZoqgE2mQ9WDeMFr+0dyt0t1KROuv+wSr4UX/8UBbFpKpWm5eson2sxBPJPaavtHUsj2mul4Rqdnyw8fmTsZJj71i6Zp4tzeKeFP6+dqnDMtI8c84jmYkKszJ8Id882ZJ+ySKbJW1YhE7T45fOyw+Ld7xLejmkvv07yUpCb/ZM0rmqsGvXmvTokeW1x2bnr3/O9znulhOaxpou04LL17zXx+rl/Uz+dXuhST0PaZnH8eCR1LydWFhaauSuKIXzzbfdXtWaKc1EsdtVD14rrEcbcw7+b8+t0pd2Fjyt2b5aSOmpBzR/zifNYjvhd90vX+iEzqKQn9wi7OZ13iP1E9Z/42LaUpszHTPpvxY0Sidk08M8f/9LAc1uxmgJJpGX7TPr/xUT1e2k9cNj/bGpWRaZHZ86i6XvMRDE18r0cldrxXwvsPy0C1oTOZ7BStXk7OmQDW2GdbHlpNFcAaKX/cXqe1b7b0Z3PEVU8Ez/G85I7bawKbzKbo8bw5LKXpkpRKJZkoDEvquF/smibhzFIhbFryJzql881hs5X+/YgMpK+aJ++S+eYaGcAenCVTSY1Gxa5pYl/4LNOqu0vqKMX0g1JHLYNu9qrMBsRCTNq1djmcNX+f/uawaPYuSelmsIvaa4PdzHHkkd7s/5KoveZOrWQ+r9iZnJDp0rTZiJ0NbrWqDddXEnJVH5GrtUFMBbBV1bSzEB806wYXFHQma9+sFBn5Aqw/fbI6JhWnf0uQ8MtOfmJthVtP0lLtOtfPxBm0hwi/6iD7n2zYdsbQN7jx7emiw+rFaauOmFT/1Yh+s7rc6W782VZ2bQP9YpbMlzHi129hAQpfx8l4AvgY5J+O55j7T0oG+iVo2/igpvs3hqW9g+4tWeJD8//Xll4wx786nA84V8P9pI56hPyw1FHLWN+VHGm8uDaZK9RHMxSsbbg3acw80uD8TQB74QjBM1NYnXDrxy3V8W2d9MlBHHvDBNqfxroJrDbzfC5fPE8KF25rgQNdSX600Qe3LHNjprd1kof6yJZ1CkPgfM5C4WgfuZp/aWZ8V4TNNp5Uz1OsiiadxPHgWR1tOC/rGBXmUk+N5Uhio+WrCN3XNIzbbSROhvA+BeyOMpjbRc++Ei5LEWOdl8FTAVzrwfhNCO9Jg+wnEdKjBtb+KIHqXANjqAf3q0k4lKHkyxPsSmIAga/n6hL4tB+o5pv7PMmRj92Efl+Tb648iWF4cdof9rPGSdehELHfDpLZHcW7HsAgdyELuB/49t9P6qhHx11SR90DfTyD9YUwro0AZQq5LK6XwrStB9B40u7GON1P/y0fPW/9Emf7ILmXeuiecmEZN3jcM8jgbvNRCv+hCOnXI/R8b6VsceBvT5F8N4X7YB//0O4mMdpNz74SXhvoUy24Xw3h1ixYjwbIpgfJbushWjPz1/hrEee2gDomVkujbwGbh9nPXjtGkT/RvkSXwv2YltKVAem8j381Mv3NYTMT+EpWa80yxwftR4Zl+spH4lkwpvTgulFHJHq31FGKOYlqqdRRD50JGdjRLoe/Uf2Hq0V1IS6bE/8bPiJfZKpddQbFXAGry1knkfD9sMC1ApbnW+8xi4NB+pMcodc7HpFkpxZcB5PEH+uje9RLqlSiVPPK7n1Ak5f/nCP5YsC8+1aWVB7NYrzhXZw66iFUuZxk8PEggW0Pe09I4/ydiEijK9E8dJK/7SC34zNcZw8xWM0soT0fpv/gnf9lxLLdzNCzb5xdJ0I47+EhTf10kO7LfmLHvKrbQlEa5WaOvpf7sLwzQGizeoR5tagA9oPpZD8rYnvJayaqXUtu62S+1HHsdqvgpSgNVP7zIJnH/PhV8FpVKoApiqIoTUmNgSmKoihNSQUwRVEUpSmpAKYoiqI0JRXAFEVRlKakApiiKIrSlFQAUxRFUZqSCmCKoihKU1IBTFEURWlKKoApiqIoTUkFMEVRFKUpqQCmKIqiNCUVwBRFUZSmpAKYoiiK0pRUAFMURVGakgpgiqIoSlNSAUxRFEVpSiqAKYqiKE1JBTBFURSlKakApiiKojQlFcAURVGUpqQCmKIoitKUVABTFEVRmpIKYIqiKEpTUgFMURRFaUoqgCmKoihNSQUwRVEUpSmpAKYoiqI0JRXAFEVRlKakApiiKIrSlFQAUxRFUZqSCmCKoihKU1IBTFEURWlKKoApiqIoTUkFMEVRFKUpqQCmKIqiNCUVwBRFUZSmpAKYoiiK0pRUAFMURVGakgpgiqKsIp3M0QAdv/bS6mhj17tZygtKGGNZijcaUjmlyakApijKqtE/OUDfE90kvsqQettJ/p0Ogp/pcwVuZojtDHLkdIFK46qpNCkVwBRFWSUF0h9naAFuAbadQYJWyHyQpjBTZJ2XSLFIYo8TS+MqqjQpFcAURVklj/N4i5X8xSz5MoAN2/PAmM7kwn5ERbkHKoApj4gy2bfM7qu12FVVHuqm9Q+FuxdsKg6C6SLFdBi3BlSKFC8BHic2DfQzB+h+I4j7uQjZZe6Uwh/cdA8tJ/pVqNwGblfW5P6edT1J0Bchq8YA78maCmCFP7TS0tJyh1cr3n19pMcXH5LFD713Wbb2FSD51wZsoNIgFXLv+gneDhPbbVuDXVU6qU8yBJ53LvF5hXJ5TV+Gl0U/E6cPL5Gjfhw30vR/7SK0w4ZxU6f8/5axgkqW1Akb7ue0OxYrvOegpeVJWp9x0PJMP+MrU/3VscFPbH+F4Mt95G42ujJNSNacCUns1kTTNAmfLc37pHRlQLrsmmiaR6Kj03WWnZTEK+ayncnJxR9/n5ePXtFE06IysjqVV9ag6Uu90m4Py7nvG12TJVwbEP/WmOQXvj9dkoncgBx+0S7aKwmpc0SLiEjp0kcS3ukS14s+8Wz3S/iDESmtoXIiItO5qHi2hyVRrJ63f5uW0tSkpPZq0v7Pw0suN28d2V6x700tq6wUYuLSNNGODEu9K8XaUpJz++1ib4q6ri1rL4CVzklY00TTOiWhL/545JgZoOoemNPDcljTRNPaJVZYYvVnw6LtGJCJla63skZNyMBOTdrfXxQe1oyJU74F9TMbYvZf+KRzp8c83pcIYJNfdYld80g0Vz0bpkYkul0T+/5z8y70jSonIjJdiEnnK70yrIuIlGTk05RcnRYzcGseiY6WZLp0t0v3tAwf0SSUXlb4kslk59IN2bWoEJN2zbPkdUupb011IQLwbYEUwOY2HBsWflihMlX98bqx6HkS/rVAFsDagWtz7WJz/eBaiwbWljXYjaSshsrFQSLn3QRfXKp7rtEKpD8usWtbbf2s+E+VKF5KMXjQu/SilSzx3ycxXgzi31I9ote58L/mwzjZTfxyg8sBXE/SvTNL60436Fmy5weJfaBzywKFr+NkPAF8DPJPx3OLz+daN86T/EMQX/uduw+rFaRYSANuvM9Zl1F+DdjsI7gtR+yr7Noes1tj1lwA0wtZDIBtTuyLPh2ncMH8yelysPDQ1Ecz5vTcl1zMXQ4Mkr9tpb96Uhn/t4jVblu0rPIwqpC7MIix2UvrxkbXZQljWRJPBvFtvnvRxcvmGDSATTZsNW/b/t4BGMQv5BpbjiLx14IkjQyRzg46fB10+HtIO83lbD9rwzaZ5MjHFUJdbu4UmsqXMmT2+8zJIHc1Tu5LwOrGsVb3+yI2Wj1OjPcy5FQEW7bHGl2B+QwKl7IA+J9zLL5LGsuSGAOsISKvLGxRlykWzGV9zrllyxcHiZ/x0/OB+bt15yDFVaq9skw3csTf6ePjP5WwPmmB22Dz9BB53TV7ESv/JU28P0Zm3IKFChW7l+5QEN/P565g5f/dT89/zWNxtvL4dxn0mxYK+Mmc8lcbKOPkPjPgRfu8Cy0ANwvE94XpL+hY2vtIHLKSfitC5noF/bsWfO9EibxQu1SZ4lCc/vczFJ+wwKRBiydM7+/9ONbVrrhC8XSEIx/mqDxhoTJlpaO3j9Av6l95c2djPLkjs7h+y2DoebOxt/As/pF59BtXdAxc0KByVhwEz5cILrUBnih5z7K2lMzpDIHXovV7TspFksePEL9UwUIF65ZWDAN4zYljOatfI2wb24AshX8F9700aB5Fje7DnGd2DMsnA9fmf1S6kpDwdk20Z0N1x8ZERqRXq46PLXzV6ZefZyovic/zD/cAaikvA2evNroWInpCuuya2PckZOJvIiJ5iW2dP2ln4mxYPJpHopfm9lrpm17xaE4JfVUdvSzExKP55KPi3KonTvnnjxV9l5BOTRP78cXjXxOf+sV/akImqmMlmr1LBq6Yf6+UDolWOx4xlZfYS3bRtvfKuZmVTw3LYbsm9j2peWNTk191id1+WM6VREQm5dz+dtHs0cUTNEREpoel194pie/u8H3lokuOgc2OBx8bqb9MdbJSo8qtmGsD4rcvsc7q8eQ5Vp1AMjUivVvvMJFrLRuNil3TpOurJqt3A62tO7CZMSyK9L/RQXKmdpM6xo/d+PdkKO5wYa1X67EcGQBrD5liGBfA7SJxfxtpp2Pp7ombOfpe7sPyzsADGxerjMU5cDSNPllEf8JL+ESMQG1/6W2DwqUStvY71PuOyhSHEoz/NIDv59Wt0uw4Ch14v+0js3c540FFBrsOkPyBz6fYdseI7VzqfkJn8HdBkoab6H4/tscA7Lg7A7gvaXg2aXAjQ/8bcXI74gzW3LVo24IEd/QR/H0/vvYorcURcpRwG2Wwm+VsTg/uYs03dsNAB1wbFnYYF0h/UMH3iY3y12Zao2B/jED1u9KsNmCQxMUCoc02Mkf99HzdSmy0B+/MqtY5aH0e+r9IkD3kw7/BXG/yeBJjSxyHBlR0chcM3Ltdde+wKpcy9G3fhf7UD/iCH0H6xSST+yLmOV2rUqDvtSBJQqT2Ve/e1zlxb4O+MSdtjgczUKCf7qb7eIbsX1zErwziX2p/3sjSd7iPwS+yWI+NkNmz4P7QasMFFP9qgBrkWJY1FcBmx7Be7iP1ge8H7UL9X0bMZV+s6TZ4zELLOitu58zlo0D81QS24xG86wEqFD7sIferPgY2P6DwdTNL5JUc7jMp/Otz9O3w0u3TsOUjuKtVqFyI4Q+NEz49QLBOvSoVsNStboH4ryOcRyd/oUjHF7vmAhgWXK9H8HpC9LdnCd21i8JB4OMUgXvf0sWu58icB3DROhuwLTj3xEjtMX8zziSJV8dX5u9/K7ZNwJk4gxfCeH/ZgY8gfT4byS0+vNvcuDwdpN6pWapSoQB1goeTrqEEFs0gmSsAPlzPzH2hxndmJ3NhqkLlcpzISQN2B+iYN55SoVIGSKMbQO2Eo6EgHZ4U3m1ePKdz9Gys1wwpkx3qJ/CrA/fYSHlUVCe5/HFxo8sYihK5DNZDHbhnu3Gr4+QLJ3KtItvOGJHrDtxn3Tjv1BhZ7ya8r0DqixLe55buNC5MqUGw5VpDkzjmxrDczzt/YPujTPFyGgDfltq7lhace5IEfm7+VrmYoo9WWtdXP75xnvhbVvw7HlwetvLFNP3rgAqwzkVgjw+MftL/c24OlsUToVhM1A1ekKPf00/9nA1Ogl8lSJwIL26tAlhc+Lta6Pm8QTOdDB1zLy39bevjybuuJv2tDk/5iefihF5wULmcJv7uAYIeB953c8vaNotmgUqR/BlgmxfX7IWnQnHUrIPfbqNwIU4B8G1zzQ805WJ1QpEP29Mzbzrpei+CdyPol9PE3+1m13N++v5cp0Y3sqRPhvBvv/fwZdvou3OBHdXJEg0qtyLGsiR+XG+Si0F2yDya/Ftqgtu3eTJjzG/Irjqd4qiB09N61+02iiMUrG04N6p50Cth7dyBVfJkTwI479g6qa9IYQjASqujdlkNR/vMwW2QPqYBp7wAAAtqSURBVNmHd6c+GxzLl7MMeryEH2QXzo8exzaWIzWq47fbsNpagTQj3+rA6k/1tjndWN/IkDvqnr3jq28VuhDXW3EDWUpUKtSNY1arWeJO3FYrlb8WyOEl8oWfCBXK4+eJ7QvQ904fyZ0JAhsBi+XO3+hYjiRgba+98MzMdPXidoJ+xqDedOzKaJY4wI4O3E8BlNEv5ylvCJEYDVExipz/sJvAezki5wuEn53fpDAuJMjsDxK9j+uY1daKlTTGlPmYyMyqKlMl8/OZu9hGlVsBubMxntxZb5KLjn4GwE/bprkvsTxuDkP4tjjQblco37KgrVu08Mqq6OSHrLR11pl4Nk+Z/KU0PB+fa0TX4XxCBbflWjsBbHb8y43zZz9w2bEcKQPAj+vn9YsYQ330XAoT/2CuxVssxLFuTNBSU04/3UPP6SwFSweBp3QqT0AurREaqnY73sgRfydGYV0b1hsZ0o8FSbzvM0+wGzn6jw4y6XBw608ZbL9LENoy/2DUPBHypcjc3xvPAU7cP7cBOunf9ZG5mSf7VISRo+6VvzN8yoGb6DJmOq1CF+JGN34PZM9nyY1VcNd8N+XzPYT/LUC83Y+XLJmCjk7t2JGOXgDw4m+3Uf5TgI6hDoqn/FixoNl99PSG6XthEGPmZvYnNhxA9nr9MQX9ivnIRujZuQHIyuUMiTFwHe3Bv1EjtwFAW9Blq5P+pB+sfuJvmTMe9c+CtO7LwMuDFD/wYbU68L0axPdejpZNC+8FdDJf5gi8Hr+//bvZTXAzRMZ0DOa6So3rBcBJcObZskaVu1+VLJmTrfjO1msQWbBsBsYcWGd3bYWRC3HASdszNvTPOgjcjJDdayf33gFiuSzlTWH8jxXRn4DCqfPYD/XiuHwe/enHKZwq4Hp/kPDss2Zlch9GiBUep+3pMpk0BL+M4dsAGFn634qjr29BP58lTys91bFYbhtk/xih/5qGe904g//eReaYF63a0Ha9sfgRIPML1MkBrp+o8a9la/QskhkTp3zmDKYFs7qWY+ape213YnGGjelJGfk0LB5tYTYGM9tB+4ma90rnJLxzQIaTXaJpfokVpmfL2Y/nRfSUhJ61S9fnM3/FnPlozhqaluE37eI6nheRvMSetYv/07vk+6jOmPIcPCcTIlJKh6UreVWG37Qvmt02Z0Si9dIO1arOvluYimt2eU2TcKZBcy6rs8bmzegrDUvvVv/szNOJZJfYtXY5nKmZhZjtlXbNLl1J8zs193m79Gbnykx83ina1qiMzG5adYZj3Vmok5LaY85Wa397xJyBWqpmk9gzdxxNj0bFo2nSObvPSzJyzCOa3TdvlmT+RLtoW0IyMJMqaabc9qjkF37VS6WOqudS79LHtpiZZexau/RemsuI0bt18ezIRpW7H3dLHZU/4RFNC0nqexGRabl6qkvss1l8JmRgZ3Um6bUB6dyfkMSbdtG2hiWli8ymndselnM1v9sPzhwrE5La66yZLSsy8nb1+qQnpMveLuH0xNz7M/tzOi+xF+01syLPSXjrYRkumfXwae1z2UsWKJ0Ni6bZJTq6Et/eo6HBd2AG6X1uAp8Zc299EcDxBbjqzdKZp0zm9y52fViz7FCQ1palnjpxEfXcpWW4zk3Px7cYOd4Nnhi+zRZgHOMaYP0/nD0VZnB9kOyOaouwmuHDnDVktr6Kb/lpu+DFfzxDYtudukJ1kr8LUvh1huT+6vjKth5i5SwHuqz4v3KbrbS/JOn+oLZLrUTx38rk3yjW3DlqeN+I4PshD23++y3uNBa1ajb4if/JhuudPo64W+nbZMOiOQmcHMBfrb9tZ5zcTweJvu/H+64FCwbGeg+hCzkCz87dQdt2d2D5ZKZMhYrVS+KzMK7ZzbLj3AZcGEfHO787sVJk5AtgWwjvd938o88K31twv5oht2duvMvybJjk1xZ6juyi7TMrWqWCw9PNSM5nzjSscr4SJz55hPi+XSSfgMpUtdxpH44FX7N+McmkP3KH7k2D5KsOgmdq3qo5tnvOlwhvMd/WXoiS+7qfniP/SJvFilax0No5fxsaWe7eVcid78P7K33J9Tn3xklMHuCAx0v8aQtWTw/ZQgeRl8JEduzC0RVnYDNw20//W+MMvmDg3ObDvQFAR78ErjcCeDdQHQ+14j7VioaZwSX8mZXgBV91tmzF7Pb+l2ucPfXfSP4kSGa7DTDQx8G5zYkNKP+POD0XDdwbswy+l0H/roIzegC3Bsb5DFlrG6Elxr/0b0fAGliyF0mpo9ERtHHMFvi8OzAREclL1K6JZ+b9awPi0+zS9dU3ErVr0n5kLvHodLZX7JrHvAuYKkmpNClXc+dk4KBHNM0jH11Z6m9PyLmDnRL6tPrsWfGcDFRb8xOf+s1We2la6qeHW6E7sLqfPXzMfbT4ucKZZ27sC59lWnV5iW1dOlenUvV9SkJauPo83QrQzXNiNpdiISbtWrscrt7BT39zWDR7l6T0aSlNieSP20WbuXMSqT6zp4nnzf8uvfaaO7Vq7tbO5IRMl6bNZ+Tm9QLMKMm5/ebzfFf1Ebm6KLH0hAzs0MT+pkro+0OsoVmID5oV60Yo6JPzZ619mydrQOtGG1Ah90Wc4gthul/YiNUJt37cUm0R6qRPDuLYGybQrtP3nA3XngyWLV4Cr/lxb3Hh+El1nUaB7OWZ/0NVIfdukCMVL/4NJXIXsyQ/jVAogfl8UgZvpw8++Seil1fhv/4ZBkWc2J5+NCZvW9o76N6SJT40f97mTMqyDucDztVwP6mjHiE/LHXUMtZ3JUcaL65N1bN3NEPB2oZ7k8bMIw3O3wSwF44QPKOjWVvh1pO0VP++fibOoD1E+NVt2DaB1fYkGlC+eJ4ULtzWAge6kvxoow9uWebGTG/rJA/1kS3rFIbA+ZyFwtE+cgtP7bE08QteejpXYdz7IbZ2JnE0gMMZhJPG/IHo0QxZqwPjeIgDZ29R0rpJfujHaQHn8UFyL/XQPeXCMm7wuGeQwd0uNCp4D/rJXiqS/kMPxdFb+N/twb0ewCD9n90EvjC7foKlIwTeyWGQo+OTmZo4ifg1wIb9lzYSp48Qbw/VDCYvl0HmUJD+McNMl/VmgOKHLsKf9sw9J/NvOsXNbgKLEiU/rJx0HQoR++0gmd3R6vN/BrkLWcCN0/5gA/n9pI56dNwlddQ90MczWF8I49oIUKaQy+J6KUzbegCNJ+1ujNP99N/y0fOWDdu6KIO5XfTsK+GyFDHWeRk8FcC1HiqHIqRfj9DzvZWyxYG/PUXy3RTug338Q7ubxGg3PftKeG2gT7XgfjWEW7NgPRogmx4ku62H6Lzu/jKZUzE4ODjbja4sU6NvARvq+5SEtNpUPnO3+SuazGW6JFdPdUo4sxL9IcvoQryDiVO+Zf//pYfHtIwc85j/b+nKR+JZkGpscTfyahmR6N1SRylmF/hSqaMeQtPfHBb79qiMTDW6Js3nEe5CBNZ7CBzSiZ2Z6V6qTnOtk+n+vlhgvGDB/cxKtPZdhL7uurcnxio5kp9aCL5658zfDx8LroNJ4o/10T3qJVUqUap5ZZeVWmsF/DlH8sUAXpU66o7Ko1mMN7z1H8Z/2FxP0v2ehfgXYVyr/bzaQ+jvREQaXYmGupmjb0cPlv8SgUjEzKcI2F6KEXt5ZTp6Kud7CP7rLuJ7H1zGjzq1IPfuLvqeiDDQ0HooiqKsDBXAAG4WSJ4B727nw3tnUi4weBb8L6vgpSjKw0EFMEVRFKUpPdpjYIqiKErTUgFMURRFaUoqgCmKoihNSQUwRVEUpSmpAKYoiqI0JRXAFEVRlKakApiiKIrSlFQAUxRFUZqSCmCKoihKU1IBTFEURWlKKoApiqIoTUkFMEVRFKUpqQCmKIqiNCUVwBRFUZSm9P8Bo2ml5ovyA0MAAAAASUVORK5CYII=)"
      ],
      "metadata": {
        "id": "tkPjlX-7O2xI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# step3. position embedding\n",
        "pos_mat = torch.arange(max_position_len).reshape((-1, 1)) # [5, 1]\n",
        "#print(pos_mat.shape)\n",
        "i_mat = torch.pow(10000, torch.arange(0, 8, 2).reshape((1, -1))/model_dim)\n",
        "#print(torch.arange(0, 8, 2).reshape((1, -1)))\n",
        "#print(i_mat.shape) # [1, 4]\n",
        "#print(i_mat)\n",
        "pe_embedding_table = torch.zeros(max_position_len, model_dim) # [5, 8]\n",
        "pe_embedding_table[:, 0::2] = torch.sin(pos_mat / i_mat) # 广播机制\n",
        "pe_embedding_table[:, 1::2] = torch.cos(pos_mat / i_mat)\n",
        "\n",
        "pe_embedding = nn.Embedding(max_position_len, model_dim)\n",
        "pe_embedding.weight = nn.Parameter(pe_embedding_table, requires_grad=False)\n",
        "\n",
        "src_pos = torch.cat([torch.unsqueeze(torch.arange(max(src_len)), 0) for _ in src_len]).to(torch.int32)\n",
        "print(src_pos)\n",
        "tgt_pos = torch.cat([torch.unsqueeze(torch.arange(max(tgt_len)), 0) for _ in tgt_len]).to(torch.int32)\n",
        "\n",
        "src_pe_embedding = pe_embedding(src_pos)\n",
        "tgt_pe_embedding = pe_embedding(tgt_pos)\n",
        "print(src_pe_embedding.shape)\n",
        "print(src_pe_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aUr9bUTOE_k",
        "outputId": "9883fa25-62b4-40c4-d62c-f7bb27c3387b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2, 3],\n",
            "        [0, 1, 2, 3]], dtype=torch.int32)\n",
            "torch.Size([2, 4, 8])\n",
            "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
            "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
            "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
            "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
            "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
            "           9.9955e-01,  3.0000e-03,  1.0000e+00]],\n",
            "\n",
            "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
            "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
            "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
            "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
            "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
            "           9.9955e-01,  3.0000e-03,  1.0000e+00]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step4. 构造encoder的self-attention mask\n",
        "# 也就是对padding为0的值设置为-inf, 不为0的设置为1\n",
        "# mask 的shape：[batch_size, max_src_len, max_src_len] 值为1或-inf\n",
        "valid_encoder_pos = torch.cat([torch.unsqueeze(F.pad(torch.ones(L), (0, max(src_len) - L)), 0) for L in src_len], 0) # 有效位置\n",
        "#print(valid_encoder_pos)\n",
        "#print(valid_encoder_pos.shape)\n",
        "valid_encoder_pos = torch.unsqueeze(valid_encoder_pos, 2)\n",
        "#print(valid_encoder_pos.shape)\n",
        "# 根据有效位置构建有效矩阵\n",
        "valid_encoder_pos_matrix = torch.bmm(valid_encoder_pos, valid_encoder_pos.transpose(1, 2))\n",
        "#print(valid_encoder_pos_matrix)\n",
        "\n",
        "# 无效矩阵，方便做矩阵乘法\n",
        "invalid_encoder_pos_matrix = 1 - valid_encoder_pos_matrix\n",
        "mask_encoder_self_attention = invalid_encoder_pos_matrix.to(torch.bool)\n",
        "\n",
        "# test\n",
        "score = torch.randn(batch_size, max(src_len), max(src_len))\n",
        "masked_score = score.masked_fill(mask_encoder_self_attention, -1e9)\n",
        "prob = F.softmax(masked_score, -1)\n",
        "\n",
        "print(src_len)\n",
        "print(score)\n",
        "print(masked_score)\n",
        "print(prob)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJJuGwdlQISp",
        "outputId": "f82c9cd7-0743-4dc9-e08c-9a3e0a49cca4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 4], dtype=torch.int32)\n",
            "tensor([[[-0.3556,  0.2798, -0.2408, -0.0356],\n",
            "         [-1.6233, -0.9366, -0.6613, -0.1839],\n",
            "         [ 0.1107, -0.0938,  0.8793, -0.8160],\n",
            "         [ 1.0289, -0.9160,  0.3753,  0.5929]],\n",
            "\n",
            "        [[ 0.3031, -1.1049,  1.9737,  0.2339],\n",
            "         [ 1.1128,  0.3577,  0.0224,  0.4413],\n",
            "         [ 2.0383, -0.1456,  0.5847, -1.0369],\n",
            "         [-0.6189, -1.5956, -0.2806, -0.7965]]])\n",
            "tensor([[[-3.5558e-01,  2.7985e-01, -1.0000e+09, -1.0000e+09],\n",
            "         [-1.6233e+00, -9.3664e-01, -1.0000e+09, -1.0000e+09],\n",
            "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "        [[ 3.0310e-01, -1.1049e+00,  1.9737e+00,  2.3392e-01],\n",
            "         [ 1.1128e+00,  3.5775e-01,  2.2442e-02,  4.4133e-01],\n",
            "         [ 2.0383e+00, -1.4560e-01,  5.8472e-01, -1.0369e+00],\n",
            "         [-6.1891e-01, -1.5956e+00, -2.8062e-01, -7.9654e-01]]])\n",
            "tensor([[[0.3463, 0.6537, 0.0000, 0.0000],\n",
            "         [0.3348, 0.6652, 0.0000, 0.0000],\n",
            "         [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "         [0.2500, 0.2500, 0.2500, 0.2500]],\n",
            "\n",
            "        [[0.1335, 0.0326, 0.7094, 0.1245],\n",
            "         [0.4316, 0.2028, 0.1451, 0.2205],\n",
            "         [0.7181, 0.0809, 0.1678, 0.0332],\n",
            "         [0.2765, 0.1041, 0.3878, 0.2315]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step5. intra-attention 的mask\n",
        "# Q @ K^T shape: [batch_size, tgt_seq_len, src_seq_len]\n",
        "valid_encoder_pos = torch.cat([torch.unsqueeze(F.pad(torch.ones(L), (0, max(src_len) - L)), 0) for L in src_len], 0) # src有效位置\n",
        "valid_encoder_pos = torch.unsqueeze(valid_encoder_pos, 2)\n",
        "\n",
        "valid_decoder_pos = torch.cat([torch.unsqueeze(F.pad(torch.ones(L), (0, max(tgt_len) - L)), 0) for L in tgt_len], 0) # tgt有效位置\n",
        "valid_decoder_pos = torch.unsqueeze(valid_decoder_pos, 2)\n",
        "\n",
        "cross_attention_pos_matrix = torch.bmm(valid_decoder_pos, valid_encoder_pos.transpose(1, 2))\n",
        "print(valid_encoder_pos, valid_decoder_pos, cross_attention_pos_matrix)\n",
        "\n",
        "invalid_cross_pos_matrix = 1 - cross_attention_pos_matrix\n",
        "mask_cross_self_attention = invalid_cross_pos_matrix.to(torch.bool)\n",
        "print(mask_cross_self_attention)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxqRAei-dFff",
        "outputId": "10a00e1c-0b12-4f28-8c70-3f9c2dc5a5d0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1.],\n",
            "         [1.],\n",
            "         [0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[1.],\n",
            "         [1.],\n",
            "         [1.],\n",
            "         [1.]]]) tensor([[[1.],\n",
            "         [1.],\n",
            "         [1.],\n",
            "         [1.]],\n",
            "\n",
            "        [[1.],\n",
            "         [1.],\n",
            "         [1.],\n",
            "         [0.]]]) tensor([[[1., 1., 0., 0.],\n",
            "         [1., 1., 0., 0.],\n",
            "         [1., 1., 0., 0.],\n",
            "         [1., 1., 0., 0.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [0., 0., 0., 0.]]])\n",
            "tensor([[[False, False,  True,  True],\n",
            "         [False, False,  True,  True],\n",
            "         [False, False,  True,  True],\n",
            "         [False, False,  True,  True]],\n",
            "\n",
            "        [[False, False, False, False],\n",
            "         [False, False, False, False],\n",
            "         [False, False, False, False],\n",
            "         [ True,  True,  True,  True]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step6. 构建decoder self-attention mask\n",
        "valid_decoder_tril_matrix = torch.cat([torch.unsqueeze(F.pad(torch.tril(torch.ones((L, L))), (0, max(tgt_len) - L, 0, max(tgt_len)- L)), 0) for L in tgt_len], 0)\n",
        "print(valid_decoder_tril_matrix)\n",
        "\n",
        "invalid_decoder_tril_matrix = 1 - valid_decoder_tril_matrix\n",
        "mask_decoder_self_attention = invalid_decoder_tril_matrix.to(torch.bool)\n",
        "print(mask_decoder_self_attention)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw7Smu3Bggtm",
        "outputId": "d6930220-0b73-442f-e7f0-64040198eb86"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 0., 0., 0.],\n",
            "         [1., 1., 0., 0.],\n",
            "         [1., 1., 1., 0.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 0., 0., 0.],\n",
            "         [1., 1., 0., 0.],\n",
            "         [1., 1., 1., 0.],\n",
            "         [0., 0., 0., 0.]]])\n",
            "tensor([[[False,  True,  True,  True],\n",
            "         [False, False,  True,  True],\n",
            "         [False, False, False,  True],\n",
            "         [False, False, False, False]],\n",
            "\n",
            "        [[False,  True,  True,  True],\n",
            "         [False, False,  True,  True],\n",
            "         [False, False, False,  True],\n",
            "         [ True,  True,  True,  True]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step7. scaled_self_attention\n",
        "def scaled_dot_self_attention(Q, K, V, attention_mask):\n",
        "  \"\"\"\n",
        "  Q: [batch_size*num_head, seq_len, model_dim/num_head]\n",
        "  K: [batch_size*num_head, seq_len, model_dim/num_head]\n",
        "  attention_mask: [batch_size, n_heasd, seq_len, seq_len]\n",
        "  \"\"\"\n",
        "  score = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # [batch_size x n_heads x len_q x len_k]\n",
        "  print(score.shape)\n",
        "  mask_score = score.masked_fill(attention_mask, -1e9)\n",
        "  prob = F.softmax(mask_score, -1)\n",
        "  context = torch.matmul(prob, V)\n",
        "  return context, prob"
      ],
      "metadata": {
        "id": "fqEMIZ6Ci3dt"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        ## 输入进来的维度分别是 [batch_size x n_heads x len_q x d_k]  K： [batch_size x n_heads x len_k x d_k]  V: [batch_size x n_heads x len_k x d_v]\n",
        "        ##首先经过matmul函数得到的scores形状是 : [batch_size x n_heads x len_q x len_k]\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)\n",
        "\n",
        "        ## 然后关键词地方来了，下面这个就是用到了我们之前重点讲的attn_mask，把被mask的地方置为无限小，softmax之后基本就是0，对q的单词不起作用\n",
        "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
        "        attn = nn.Softmax(dim=-1)(scores)\n",
        "        context = torch.matmul(attn, V)\n",
        "        return context, attn"
      ],
      "metadata": {
        "id": "nPYdzQz6meUS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step8 mutil-head self attention layer\n",
        "d_k = 2\n",
        "d_v = 2\n",
        "n_heads = 2\n",
        "class MutilHeadAttention(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MutilHeadAttention, self).__init__()\n",
        "    # Q, K, V 映射线性层\n",
        "    self.W_Q = nn.Linear(model_dim, d_k * n_heads)\n",
        "    self.W_K = nn.Linear(model_dim, d_k * n_heads)\n",
        "    self.W_V = nn.Linear(model_dim, d_v * n_heads)\n",
        "    self.linear = nn.Linear(n_heads * d_v, model_dim)\n",
        "    self.layer_norm = nn.LayerNorm(model_dim)\n",
        "\n",
        "  def forward(self, Q, K, V, attn_mask):\n",
        "    residual, batch_size = Q, Q.size(0)\n",
        "\n",
        "    q_s = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)\n",
        "    k_s = self.W_K(Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)\n",
        "    v_s = self.W_V(Q).view(batch_size, -1, n_heads, d_v).transpose(1, 2)\n",
        "\n",
        "    attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)\n",
        "\n",
        "    context, attn = scaled_dot_self_attention(q_s, k_s, v_s, attn_mask)\n",
        "    #context, attn = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)\n",
        "    context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * d_v) # context: [batch_size x len_q x n_heads * d_v]\n",
        "    output = self.linear(context)\n",
        "    return self.layer_norm(output + residual), attn # output: [batch_size x len_q x d_model]"
      ],
      "metadata": {
        "id": "XyLzxxxReyRB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mask_encoder_self_attention.shape)\n",
        "print(src_pe_embedding.shape)\n",
        "mh = MutilHeadAttention()\n",
        "output, attns = mh(src_pe_embedding, src_pe_embedding, src_pe_embedding, mask_encoder_self_attention)\n",
        "print(output.shape, attns.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSOJQuD6jrK1",
        "outputId": "37e54f33-33ca-4b71-f720-7e582cbda5ec"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4, 4])\n",
            "torch.Size([2, 4, 8])\n",
            "torch.Size([2, 2, 4, 4])\n",
            "torch.Size([2, 4, 8]) torch.Size([2, 2, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP Example\n",
        "batch, sentence_length, embedding_dim = 20, 5, 10\n",
        "embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
        "layer_norm = nn.LayerNorm(embedding_dim)\n",
        "# Activate module\n",
        "output1 = layer_norm(embedding)\n",
        "print(output1.shape)\n",
        "# Image Example\n",
        "N, C, H, W = 20, 5, 10, 10\n",
        "input = torch.randn(N, C, H, W)\n",
        "# Normalize over the last three dimensions (i.e. the channel and spatial dimensions)\n",
        "# as shown in the image below\n",
        "layer_norm = nn.LayerNorm([C, H, W])\n",
        "output = layer_norm(input)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj4qTcJhgsOp",
        "outputId": "527d4909-1e9f-4b3c-9677-b00198d127da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 5, 10])\n",
            "torch.Size([20, 5, 10, 10])\n"
          ]
        }
      ]
    }
  ]
}